<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Style Transfer Debugging</title>
</head>
<body>
    <h2>Real-Time Style Transfer with Debugging</h2>

    <!-- Upload buttons for content (game frame) and style images -->
    <input type="file" id="contentUpload" accept="image/*" />
    <input type="file" id="styleUpload" accept="image/*" />

    <!-- Canvases for displaying images -->
    <canvas id="contentCanvas" width="256" height="256"></canvas>
    <canvas id="styleCanvas" width="256" height="256"></canvas>
    <canvas id="outputCanvas" width="256" height="256"></canvas>

    <!-- Include TensorFlow.js and the style transfer model -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.6.0/dist/tf.min.js"></script>

    <script>
        let styleModel;

        // Load the style transfer model
        async function loadModel() {
            try {
                styleModel = await tf.loadGraphModel('Model/model.json');
                console.log("Model loaded successfully.");
            } catch (error) {
                console.error("Error loading model:", error);
            }
        }

        // Convert image input to canvas for use in TensorFlow
        function imageToCanvas(imageFile, canvas) {
            const ctx = canvas.getContext('2d');
            const img = new Image();
            img.src = URL.createObjectURL(imageFile);
            img.onload = () => {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
                console.log("Image loaded onto canvas:", canvas.id);
            };
        }

        // Perform style transfer
        async function applyStyleTransfer() {
            if (!styleModel) {
                console.error("Model not loaded yet.");
                return;
            }

            // Get images from the canvases
            const contentCanvas = document.getElementById('contentCanvas');
            const styleCanvas = document.getElementById('styleCanvas');
            const outputCanvas = document.getElementById('outputCanvas');

            // Convert the content and style canvases to tensors
            const contentTensor = tf.browser.fromPixels(contentCanvas).expandDims(0).toFloat().div(255);
            const styleTensor = tf.browser.fromPixels(styleCanvas).expandDims(0).toFloat().div(255);

            try {
                // Run the style transfer model with corrected input keys
                const results = await styleModel.executeAsync({ 
                    'placeholder': contentTensor, 
                    'placeholder_1': styleTensor 
                }, 'Identity');

                console.log("Style transfer applied successfully.");
                console.log("Model results:", results);

                if (results) {
                    // Rescale the output tensor values to ensure they are within [0, 1] for rendering
                    const outputTensor = results.squeeze();
                    const scaledOutput = outputTensor.sub(outputTensor.min()).div(outputTensor.max().sub(outputTensor.min()));

            // Check and display min and max values for debugging
            const minVal = scaledOutput.min().dataSync()[0];
            const maxVal = scaledOutput.max().dataSync()[0];
            console.log("Output Tensor - Min Value:", minVal, "Max Value:", maxVal);


                    // Display the stylized image on the output canvas
                    await tf.browser.toPixels(scaledOutput, outputCanvas);
                    console.log("Stylized image rendered to output canvas.");
                    
                    // Clean up tensors
                    outputTensor.dispose();
                    scaledOutput.dispose();
                } else {
                    console.error("No output tensor received from model.");
                }
            } catch (error) {
                console.error("Error applying style transfer:", error);
            } finally {
                // Clean up tensors
                contentTensor.dispose();
                styleTensor.dispose();
            }
        }

        // Event listeners for file uploads
        document.getElementById('contentUpload').addEventListener('change', (event) => {
            imageToCanvas(event.target.files[0], document.getElementById('contentCanvas'));
        });
        document.getElementById('styleUpload').addEventListener('change', (event) => {
            imageToCanvas(event.target.files[0], document.getElementById('styleCanvas'));
        });

        // Apply style transfer only when both images have been uploaded
        document.getElementById('contentUpload').addEventListener('change', () => {
            if (document.getElementById('styleUpload').files.length > 0) {
                applyStyleTransfer();
            }
        });
        document.getElementById('styleUpload').addEventListener('change', () => {
            if (document.getElementById('contentUpload').files.length > 0) {
                applyStyleTransfer();
            }
        });

        // Load the model on page load
        loadModel();
    </script>
</body>
</html>
